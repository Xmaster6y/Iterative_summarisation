{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4-VUn1NllcI"
      },
      "source": [
        "# Iterative summarization training notebook\n",
        "\n",
        "## Goals\n",
        "\n",
        "* This notebook propose a fine-tuning of GPT-2 for summarization in order to interpret this process. \n",
        "* The reverse training is also performed to create an exemplificator model.\n",
        "\n",
        "The training is facilitated by Neel Nanda's library [TransformerLens](https://github.com/neelnanda-io/TransformerLens). \n",
        "See this project's [GitHub](https://github.com/Xmaster6y/Iterative_summarisation) for more details.\n",
        "\n",
        "## Notes\n",
        "\n",
        "* For training use this notebook with a GPU runtime `Runtime>Change runtime type>GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzRZwHNXp9Xi"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umc9sb98T4gF"
      },
      "source": [
        "### Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX-EVgF_T67w"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0QZjGnOSju_"
      },
      "source": [
        "### Classic libraries imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-_bc5gGS0rR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import evaluate\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import get_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2oY3m8Oikx8"
      },
      "source": [
        "### External toolboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amE7WM8binRG"
      },
      "outputs": [],
      "source": [
        "from transformer_lens import HookedTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTE-xUovScqZ"
      },
      "source": [
        "### Dataset import\n",
        "\n",
        "Note that the original dataset is really really big, impossible to load it even with linecache. I couldn't even split it with the lunix command. Anyway I wouldn't have time to train with such a tremendous dataset hence the reduction.\n",
        "\n",
        "Also note that the dataset is ill-formated i.e. not really a json-file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESZTK7o6SYiZ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./Movies_and_TV_5.json.gz') and not os.path.exists('./dataset.json'):\n",
        "  !wget https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Movies_and_TV_5.json.gz --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0nhNAKTPZ-"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./dataset.json'):\n",
        "  if not os.path.exists('./Movies_and_TV_5.json.gz'):\n",
        "    raise FileNotFoundError\n",
        "  else:\n",
        "    !gzip -d Movies_and_TV_5.json.gz\n",
        "    !mv Movies_and_TV_5.json dataset.json\n",
        "n = 2000\n",
        "!head -n $n dataset.json > mini_dataset.json\n",
        "out = !wc -l mini_dataset.json\n",
        "n = int(out[0].split()[0])\n",
        "n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jluxqqj2V576"
      },
      "outputs": [],
      "source": [
        "train_size = n // 2\n",
        "eval_size = n - train_size\n",
        "!head -n $train_size mini_dataset.json > train.json\n",
        "!tail -n $eval_size mini_dataset.json > eval.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecq-SAFRfzUk"
      },
      "outputs": [],
      "source": [
        "class SummarizationDataset(Dataset):\n",
        "    \"\"\"Text dataset for summarisation.\"\"\"\n",
        "    def __init__(self, dataset_path='./mini_dataset.json'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataset_path (string): Path to the dataset of texts.\n",
        "        \"\"\"\n",
        "        with open(dataset_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        raw_records = list(map(json.loads, lines))\n",
        "        self.records = [r for r in raw_records if 'reviewText' in r.keys()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return f\"[review]: {self.records[idx]['reviewText']}\\n[summary]: {self.records[idx]['summary']}\"\n",
        "\n",
        "  \n",
        "class ExamplificationDataset(SummarizationDataset):\n",
        "    \"\"\"Text dataset for examplification.\"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        return f\"[summary]: {self.records[idx]['summary']}\\n[review]: {self.records[idx]['reviewText']}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDMsi1EPp_St"
      },
      "source": [
        "## Model loading and fine-tuning\n",
        "\n",
        "The model is trained using the dataloaders defined above on the chosen task.\n",
        "\n",
        "* To avoid doing the training over the weights are automatically loaded from Drive unless stated otherwise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCBkgZv0qCny"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.cuda.empty_cache()\n",
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diJlNNp-aQZg"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, lr_scheduler, dl, epochs, pb):\n",
        "    model.train()    \n",
        "    for epoch in range(epochs):\n",
        "        for idx, batch in enumerate(dl):\n",
        "             with torch.set_grad_enabled(True):\n",
        "                optimizer.zero_grad()\n",
        "                loss = model(batch, return_type=\"loss\")\n",
        "                loss.backward()\n",
        "                optimizer.step() \n",
        "                lr_scheduler.step()\n",
        "                pb.update(1)\n",
        "                if idx % 50 == 0:\n",
        "                    print({\"loss\": float(loss)}, idx+epoch*len(dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HOZOf80n0YQ"
      },
      "outputs": [],
      "source": [
        "task = 'exp'\n",
        "weight_file = f'./{task}_weights.pt'\n",
        "re_train = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Q8asI5aVHN"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "if task == 'sum':\n",
        "    train_dataset = SummarizationDataset(dataset_path='./train.json')\n",
        "    eval_dataset = SummarizationDataset(dataset_path='./eval.json')\n",
        "else:\n",
        "    train_dataset = ExamplificationDataset(dataset_path='./train.json')\n",
        "    eval_dataset = ExamplificationDataset(dataset_path='./eval.json')\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "eval_dl = DataLoader(eval_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "lr = 3e-4\n",
        "epochs = 1\n",
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr=lr)\n",
        "num_training_steps = epochs * len(train_dl)\n",
        "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "if not os.path.exists(weight_file):\n",
        "    if task == 'sum':\n",
        "        !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tPU5mHCXcAxZJJHvv9XyT-MzgoeSWUk9\" -O $weight_file  && rm -rf /tmp/cookies.txt\n",
        "    else:\n",
        "        !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1--qi-Rzhff4OcAtknrSrzfDzgNC9z5mQ\" -O $weight_file  && rm -rf /tmp/cookies.txt\n",
        "\n",
        "if not os.path.exists(weight_file) or re_train:\n",
        "    train(model, optimizer, lr_scheduler, train_dl, epochs, progress_bar)\n",
        "else:\n",
        "    model.load_state_dict(torch.load(weight_file))\n",
        "    model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb9nwUWe5qQC"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), weight_file )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdTpp_CSpV0m"
      },
      "source": [
        "## Model evaluation\n",
        "\n",
        "The model is evaluated using the ROUGE metric. This only gives insight on the meaningfulness of the training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_func(batch, sep=\"summary\"):\n",
        "    samples = [s.split(f'\\n[{sep}]: ') for s in batch]\n",
        "    return [s[0]+f'\\n[{sep}]: ' for s in samples]"
      ],
      "metadata": {
        "id": "2XClq8YJQNQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUTyJ85KpZGT"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, metric, dl, split_func, max_iter=100, max_new_tokens=15):\n",
        "    model.eval()\n",
        "    for i, batch in enumerate(dl):\n",
        "        with torch.no_grad():\n",
        "            to_pred = split_func(batch)\n",
        "            predictions = [model.generate(prompt, max_new_tokens=max_new_tokens) for prompt in to_pred]\n",
        "            metric.add_batch(predictions=predictions, references=batch)\n",
        "        if i >= max_iter:\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_frFriHk6Yy"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"rouge\")\n",
        "if task == \"sum\":\n",
        "    sf = lambda b: split_func(b, sep=\"summary\")\n",
        "else:\n",
        "    sf = lambda b: split_func(b, sep=\"review\")\n",
        "max_new_tokens = 15\n",
        "max_iter = 100\n",
        "model_eval(model, metric, eval_dl, sf, max_iter, max_new_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute()"
      ],
      "metadata": {
        "id": "e1GITqCeVeMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}